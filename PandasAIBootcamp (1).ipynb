{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A18BEV26UFjW"
   },
   "source": [
    "# Table of Contents:\n",
    "# 1. Introduction to Pandas\n",
    "# 2. Creating Series and DataFrames\n",
    "# 3. Loading and Exploring Data\n",
    "# 4. Data Selection and Indexing\n",
    "# 5. Data Cleaning and Handling Missing Values\n",
    "# 6. Data Filtering and Querying\n",
    "# 7. Data Aggregation and Grouping\n",
    "# 8. Data Merging and Joining\n",
    "# 9. Pivot Tables and Reshaping\n",
    "# 10. Advanced Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CSyO6snrTrX-",
    "outputId": "eb49a941-7520-4689-c0c6-dd085bec00a9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pandas version: 2.3.2\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "print(\"Pandas version:\", pd.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y1QOi-9AT6_H"
   },
   "source": [
    "# ===========================================================\n",
    "# 1. INTRODUCTION TO PANDAS\n",
    "# ===========================================================\n",
    "\n",
    "\n",
    "Pandas is a powerful data manipulation and analysis library for Python.\n",
    "It provides two main data structures:\n",
    "- Series: 1-dimensional labeled array\n",
    "- DataFrame: 2-dimensional labeled data structure (like a spreadsheet)\n",
    "\n",
    "Key Features:\n",
    "- Easy handling of missing data\n",
    "- Data alignment and merging\n",
    "- Flexible reshaping and pivoting\n",
    "- Powerful grouping functionality\n",
    "- Time series functionality\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VpdrggwmUVWv"
   },
   "source": [
    "# =================================================================\n",
    "# 2. CREATING SERIES AND DATAFRAMES\n",
    "# ================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BTNcALDcUT_r",
    "outputId": "80f85686-c764-4ca3-a68c-43ff1e707604"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "2. CREATING SERIES AND DATAFRAMES\n",
      "============================================================\n",
      "\n",
      "2.1 Creating Series:\n",
      "------------------------------\n",
      "Series from list:\n",
      "0    25\n",
      "1    30\n",
      "2    35\n",
      "3    28\n",
      "4    45\n",
      "Name: Age, dtype: int64\n",
      "\n",
      "Series from dictionary:\n",
      "Alice      25\n",
      "Bob        30\n",
      "Charlie    35\n",
      "Diana      28\n",
      "dtype: int64\n",
      "\n",
      "Series shape: (5,)\n",
      "Series dtype: int64\n",
      "Series index: [0, 1, 2, 3, 4]\n",
      "Series values: [25 30 35 28 45]\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"2. CREATING SERIES AND DATAFRAMES\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Creating a Series\n",
    "print(\"\\n2.1 Creating Series:\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "# From a list\n",
    "ages = pd.Series([25, 30, 35, 28, 45], name='Age')\n",
    "print(\"Series from list:\")\n",
    "print(ages)\n",
    "\n",
    "# From a dictionary\n",
    "person_ages = pd.Series({'Alice': 25, 'Bob': 30, 'Charlie': 35, 'Diana': 28})\n",
    "print(\"\\nSeries from dictionary:\")\n",
    "print(person_ages)\n",
    "\n",
    "# Series attributes\n",
    "print(f\"\\nSeries shape: {ages.shape}\")\n",
    "print(f\"Series dtype: {ages.dtype}\")\n",
    "print(f\"Series index: {ages.index.tolist()}\")\n",
    "print(f\"Series values: {ages.values}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jxdtOvNeU-fb",
    "outputId": "bee52697-c832-4b23-850a-bb43c4a18cf4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2.2 Creating DataFrames:\n",
      "------------------------------\n",
      "DataFrame from dictionary:\n",
      "      Name  Age      City  Salary\n",
      "0    Alice   25  New York   50000\n",
      "1      Bob   30    London   60000\n",
      "2  Charlie   35     Paris   75000\n",
      "3    Diana   28     Tokyo   55000\n",
      "4      Eve   45    Sydney   80000\n",
      "\n",
      "DataFrame from lists:\n",
      "      Name  Age\n",
      "0    Alice   25\n",
      "1      Bob   30\n",
      "2  Charlie   35\n",
      "\n",
      "DataFrame shape: (5, 4)\n",
      "DataFrame columns: ['Name', 'Age', 'City', 'Salary']\n",
      "DataFrame index: [0, 1, 2, 3, 4]\n",
      "DataFrame dtypes:\n",
      "Name      object\n",
      "Age        int64\n",
      "City      object\n",
      "Salary     int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Creating a DataFrame\n",
    "print(\"\\n2.2 Creating DataFrames:\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "# From a dictionary\n",
    "data_dict = {\n",
    "    'Name': ['Alice', 'Bob', 'Charlie', 'Diana', 'Eve'],\n",
    "    'Age': [25, 30, 35, 28, 45],\n",
    "    'City': ['New York', 'London', 'Paris', 'Tokyo', 'Sydney'],\n",
    "    'Salary': [50000, 60000, 75000, 55000, 80000]\n",
    "}\n",
    "\n",
    "df_sample = pd.DataFrame(data_dict)\n",
    "print(\"DataFrame from dictionary:\")\n",
    "print(df_sample)\n",
    "\n",
    "# From lists\n",
    "names = ['Alice', 'Bob', 'Charlie']\n",
    "ages = [25, 30, 35]\n",
    "df_from_lists = pd.DataFrame({'Name': names, 'Age': ages})\n",
    "print(\"\\nDataFrame from lists:\")\n",
    "print(df_from_lists)\n",
    "\n",
    "# DataFrame attributes\n",
    "print(f\"\\nDataFrame shape: {df_sample.shape}\")\n",
    "print(f\"DataFrame columns: {df_sample.columns.tolist()}\")\n",
    "print(f\"DataFrame index: {df_sample.index.tolist()}\")\n",
    "print(f\"DataFrame dtypes:\\n{df_sample.dtypes}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pOf_hKUwWUay"
   },
   "source": [
    "# =======================================\n",
    "# 3. LOADING AND EXPLORING DATA\n",
    "# =======================================\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "KOWIFrlhXREL"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/content/Titanic-Dataset.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Load the Titanic dataset\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m titanic=\u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m/content/Titanic-Dataset.csv\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.13/site-packages/pandas/io/parsers/readers.py:1026\u001b[39m, in \u001b[36mread_csv\u001b[39m\u001b[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[39m\n\u001b[32m   1013\u001b[39m kwds_defaults = _refine_defaults_read(\n\u001b[32m   1014\u001b[39m     dialect,\n\u001b[32m   1015\u001b[39m     delimiter,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1022\u001b[39m     dtype_backend=dtype_backend,\n\u001b[32m   1023\u001b[39m )\n\u001b[32m   1024\u001b[39m kwds.update(kwds_defaults)\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.13/site-packages/pandas/io/parsers/readers.py:620\u001b[39m, in \u001b[36m_read\u001b[39m\u001b[34m(filepath_or_buffer, kwds)\u001b[39m\n\u001b[32m    617\u001b[39m _validate_names(kwds.get(\u001b[33m\"\u001b[39m\u001b[33mnames\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[32m    619\u001b[39m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m620\u001b[39m parser = \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    622\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[32m    623\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.13/site-packages/pandas/io/parsers/readers.py:1620\u001b[39m, in \u001b[36mTextFileReader.__init__\u001b[39m\u001b[34m(self, f, engine, **kwds)\u001b[39m\n\u001b[32m   1617\u001b[39m     \u001b[38;5;28mself\u001b[39m.options[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m] = kwds[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m   1619\u001b[39m \u001b[38;5;28mself\u001b[39m.handles: IOHandles | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1620\u001b[39m \u001b[38;5;28mself\u001b[39m._engine = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.13/site-packages/pandas/io/parsers/readers.py:1880\u001b[39m, in \u001b[36mTextFileReader._make_engine\u001b[39m\u001b[34m(self, f, engine)\u001b[39m\n\u001b[32m   1878\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[32m   1879\u001b[39m         mode += \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1880\u001b[39m \u001b[38;5;28mself\u001b[39m.handles = \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1881\u001b[39m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1882\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1883\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1884\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcompression\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1885\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmemory_map\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1886\u001b[39m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1887\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding_errors\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstrict\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1888\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstorage_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1889\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1890\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.handles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1891\u001b[39m f = \u001b[38;5;28mself\u001b[39m.handles.handle\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.13/site-packages/pandas/io/common.py:873\u001b[39m, in \u001b[36mget_handle\u001b[39m\u001b[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[39m\n\u001b[32m    868\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m    869\u001b[39m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[32m    870\u001b[39m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[32m    871\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m ioargs.encoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs.mode:\n\u001b[32m    872\u001b[39m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m873\u001b[39m         handle = \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    874\u001b[39m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    875\u001b[39m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    876\u001b[39m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    877\u001b[39m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    878\u001b[39m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    880\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    881\u001b[39m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[32m    882\u001b[39m         handle = \u001b[38;5;28mopen\u001b[39m(handle, ioargs.mode)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: '/content/Titanic-Dataset.csv'"
     ]
    }
   ],
   "source": [
    "# Load the Titanic dataset\n",
    "titanic=pd.read_csv('/content/Titanic-Dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 947
    },
    "id": "dqvV_hSyX8Vz",
    "outputId": "185cbed4-9c47-4ff0-9d6f-3e73bace4ce7"
   },
   "outputs": [],
   "source": [
    "titanic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DungVOmuXtUL",
    "outputId": "8a88c455-0af7-41a0-bcb2-09263b28c3d5"
   },
   "outputs": [],
   "source": [
    "# Basic information about the dataset\n",
    "print(f\"Dataset shape: {titanic.shape}\")\n",
    "print(f\"Number of rows: {len(titanic)}\")\n",
    "print(f\"Number of columns: {len(titanic.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 538
    },
    "id": "Fz6ngc1aXw3j",
    "outputId": "8247c255-c825-4870-ff23-862c0e8c547e"
   },
   "outputs": [],
   "source": [
    "# Display first few rows\n",
    "print(\"\\nFirst 5 rows:\")\n",
    "titanic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 486
    },
    "id": "uBTWJoohYIff",
    "outputId": "54eb4803-c47a-47d0-f73c-25f41b56479e"
   },
   "outputs": [],
   "source": [
    "# Display last few rows\n",
    "print(\"\\nLast 5 rows:\")\n",
    "titanic.tail()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 371
    },
    "id": "UioDWYzfYL1s",
    "outputId": "bdd8cfb1-6838-4ef3-ffc5-791783049b8a"
   },
   "outputs": [],
   "source": [
    "# Display random sample\n",
    "print(\"\\nRandom sample of 3 rows:\")\n",
    "titanic.sample(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DzrvZNveYPzs",
    "outputId": "e8a5a19a-3b54-4796-fad6-805ce39e3234"
   },
   "outputs": [],
   "source": [
    "# Dataset info\n",
    "print(titanic.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "id": "WIga6-O7Y6yW",
    "outputId": "24931cd8-9bdf-4b25-837f-04c3325a1346"
   },
   "outputs": [],
   "source": [
    "# Describe numerical columns\n",
    "titanic.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6S5-Q26DZE3B",
    "outputId": "6054d510-2f42-47cd-e0a3-e2bd2660c992"
   },
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "print(titanic.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_OmDWbExZLRR",
    "outputId": "5f70ede3-9285-4105-e1a3-91ed336b9bff"
   },
   "outputs": [],
   "source": [
    "# Check data types\n",
    "print(titanic.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NOJWYYbYZOJ-"
   },
   "source": [
    "# =====================================================\n",
    "# 4. DATA SELECTION AND INDEXING\n",
    "# =====================================================\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UAl2hEMaZfDz",
    "outputId": "3bc6adf3-0f63-4c05-e70f-b2e7789e0257"
   },
   "outputs": [],
   "source": [
    "print(\"4. DATA SELECTION AND INDEXING\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Column selection\n",
    "print(\"\\n4.1 Column Selection:\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "# Single column (returns Series)\n",
    "ages_series = titanic['Age']\n",
    "print(f\"Type of single column selection: {type(ages_series)}\")\n",
    "print(f\"First 5 ages: {ages_series.head().tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Lgq28y82Zvbg",
    "outputId": "254f6c07-d8d1-4e7a-8b5c-2ddd3db3c14e"
   },
   "outputs": [],
   "source": [
    "# Multiple columns (returns DataFrame)\n",
    "passenger_info = titanic[['Age', 'Sex', 'Fare']]\n",
    "print(f\"\\nType of multiple column selection: {type(passenger_info)}\")\n",
    "print(\"First 3 rows of passenger info:\")\n",
    "print(passenger_info.head(3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UWLjEoNkZ8Jp",
    "outputId": "42930af6-ebca-4c21-da45-816e278f8469"
   },
   "outputs": [],
   "source": [
    "# Row selection using iloc (integer-location based)\n",
    "print(\"\\n4.2 Row Selection with iloc:\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "# Single row\n",
    "first_passenger = titanic.iloc[0]\n",
    "print(f\"First passenger:\\n{first_passenger}\")\n",
    "print(f\"\\nType of row selection: {type(first_passenger)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "izbfoOpJaUa4",
    "outputId": "1130f2c1-5584-4e9c-c8b4-2f5ecf300749"
   },
   "outputs": [],
   "source": [
    "# Multiple rows\n",
    "first_five = titanic.iloc[0:5]\n",
    "print(f\"\\nFirst 5 passengers (shape: {first_five.shape}):\")\n",
    "print(first_five)\n",
    "print(first_five[['Age', 'Sex', 'Fare']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ypg18E4RapQW",
    "outputId": "bf22724c-2cfa-47dd-d3b9-a5bc2ee9eec8"
   },
   "outputs": [],
   "source": [
    "# Specific rows\n",
    "specific_rows = titanic.iloc[[0, 5, 10]]\n",
    "print(f\"\\nSpecific rows (0, 5, 10):\")\n",
    "print(specific_rows[['Age', 'Sex', 'Fare']])\n",
    "\n",
    "# Row and column selection\n",
    "print(\"\\n4.3 Row and Column Selection:\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "# Select specific rows and columns\n",
    "subset = titanic.iloc[0:5, 1:4]  # First 5 rows, columns 1-3\n",
    "print(\"Subset (first 5 rows, columns 1-3):\")\n",
    "print(subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fSrq0TLVazpO",
    "outputId": "7fec0f30-fa38-4c90-b7c1-df67cff3d690"
   },
   "outputs": [],
   "source": [
    "# Using column names with loc\n",
    "age_sex_subset = titanic.loc[0:4, ['Age', 'Sex']]\n",
    "print(f\"\\nUsing loc with column names:\")\n",
    "print(age_sex_subset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mxiut9AKbDz6"
   },
   "source": [
    "# =====================================================\n",
    "# 5. DATA CLEANING AND HANDLING MISSING VALUES\n",
    "# ====================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vvjbmL9PbNSH",
    "outputId": "0a48137e-3f7b-4ba2-d96f-28a9bc6e644c"
   },
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"5. DATA CLEANING AND HANDLING MISSING VALUES\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\\n5.1 Identifying Missing Values:\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "# Check for missing values\n",
    "missing_counts = titanic.isnull().sum()\n",
    "print(\"Missing values per column:\")\n",
    "print(missing_counts[missing_counts > 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NwaDGj0LbQ5y",
    "outputId": "250a1a74-1f67-4796-8454-5b39c8566a42"
   },
   "outputs": [],
   "source": [
    "# Percentage of missing values\n",
    "missing_percentage = (titanic.isnull().sum() / len(titanic)) * 100\n",
    "print(\"\\nPercentage of missing values:\")\n",
    "print(missing_percentage[missing_percentage > 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1qIKy-CxbsqH",
    "outputId": "71e640ff-f703-4f5b-e73d-e27706178e97"
   },
   "outputs": [],
   "source": [
    "print(\"\\n5.2 Handling Missing Values:\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "# Create a copy for cleaning\n",
    "titanic_clean = titanic.copy()\n",
    "\n",
    "# Method 1: Drop rows with missing values\n",
    "print(f\"Original shape: {titanic_clean.shape}\")\n",
    "titanic_no_na = titanic_clean.dropna()\n",
    "print(f\"After dropping all NAs: {titanic_no_na.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6McHoWP1b2pP",
    "outputId": "aa09caf9-4c95-42e2-865a-93f0086614b1"
   },
   "outputs": [],
   "source": [
    "# Method 2: Drop specific columns with missing values\n",
    "titanic_drop_cols = titanic_clean.dropna(axis=1)\n",
    "print(f\"After dropping columns with NAs: {titanic_drop_cols.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-0BYLcQ_cUsS",
    "outputId": "76f4dcee-6340-429b-f537-321d6788e2dc"
   },
   "outputs": [],
   "source": [
    "# Method 3: Fill missing values\n",
    "# Fill numerical missing values with median\n",
    "if 'Age' in titanic_clean.columns:\n",
    "    median_age = titanic_clean['Age'].median()\n",
    "    titanic_clean['Age'].fillna(median_age, inplace=True)\n",
    "    print(f\"Filled missing ages with median: {median_age:.1f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YeU-OwuPdnSA",
    "outputId": "81f61dbd-7029-4dc0-d517-f54695f77f20"
   },
   "outputs": [],
   "source": [
    "# Fill categorical missing values with mode\n",
    "if 'Embarked' in titanic_clean.columns:\n",
    "    mode_embarked = titanic_clean['Embarked'].mode()[0]\n",
    "    titanic_clean['Embarked'].fillna(mode_embarked, inplace=True)\n",
    "    print(f\"Filled missing embarked with mode: {mode_embarked}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A28mWwX0dqTF",
    "outputId": "fe84e945-bdf4-4c34-af26-cc51c03a0d41"
   },
   "outputs": [],
   "source": [
    "# Check missing values after cleaning\n",
    "print(f\"\\nMissing values after cleaning: {titanic_clean.isnull().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dRi4wyskeTRA"
   },
   "source": [
    "# =====================================================\n",
    "# 6. DATA FILTERING AND QUERYING\n",
    "# =====================================================\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IjQpdZrZeyaF",
    "outputId": "2bf5c22f-434f-4c2d-a32c-62044cb447cc"
   },
   "outputs": [],
   "source": [
    "print(\"6. DATA FILTERING AND QUERYING\")\n",
    "\n",
    "print(\"\\n6.1 Basic Filtering:\")\n",
    "\n",
    "# Single condition\n",
    "adults = titanic_clean[titanic_clean['Age'] >= 18]\n",
    "print(f\"Number of adults (Age >= 18): {len(adults)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ax8sh5v7e7eJ",
    "outputId": "9eefc692-dc0d-461c-d853-32002bcf1b22"
   },
   "outputs": [],
   "source": [
    "# Display first few adult passengers\n",
    "print(\"First 3 adult passengers:\")\n",
    "print(adults[['Age', 'Sex', 'Survived']].head(3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tpoRWl9GfBNh",
    "outputId": "c166c5c2-2c93-424c-fab9-c16b510ac0d4"
   },
   "outputs": [],
   "source": [
    "# Multiple conditions using & (and) and | (or)\n",
    "\n",
    "young_females = titanic_clean[(titanic_clean['Age'] < 30) & (titanic_clean['Sex'] == 'female')]\n",
    "print(f\"\\nYoung females (Age < 30): {len(young_females)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9GsV2p7KfLpV",
    "outputId": "37003da2-8c18-4ce9-9710-c5d819a5208d"
   },
   "outputs": [],
   "source": [
    "# High fare or first class\n",
    "luxury_passengers = titanic_clean[(titanic_clean['Fare'] > 50) | (titanic_clean['Pclass'] == 1)]\n",
    "print(f\"Luxury passengers (fare > 50 OR first class): {len(luxury_passengers)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4PvrtEH0flVu",
    "outputId": "2e19d57b-4716-4577-8343-31eeb6c59294"
   },
   "outputs": [],
   "source": [
    "print(\"\\n6.2 Using isin() Method:\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "# Filter using isin()\n",
    "european_ports = titanic_clean[titanic_clean['Embarked'].isin(['C', 'S'])]\n",
    "print(f\"Passengers from European ports (C, S): {len(european_ports)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MrCTxaGfi6bk",
    "outputId": "dbd3b6b1-c7d0-49e7-ab7f-38b42218330f"
   },
   "outputs": [],
   "source": [
    "print(\"\\n6.3 Query Method:\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "# Using query method for complex conditions\n",
    "query_result = titanic_clean.query('Age > 30 and Fare < 20')\n",
    "print(f\"Passengers with age > 30 and fare < 20: {len(query_result)}\")\n",
    "\n",
    "# Query with string conditions\n",
    "if 'Sex' in titanic_clean.columns:\n",
    "    female_survivors = titanic_clean.query('Sex == \"female\" and Survived == 1')\n",
    "    print(f\"Female survivors: {len(female_survivors)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rYBvW_7Y2DNx",
    "outputId": "6264790b-1520-4139-e0fe-7f9b1a0efa2f"
   },
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 7. DATA AGGREGATION AND GROUPING\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"7. DATA AGGREGATION AND GROUPING\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\\n7.1 Basic Aggregations:\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "# Basic statistics\n",
    "if 'Age' in titanic_clean.columns:\n",
    "    print(f\"Mean age: {titanic_clean['Age'].mean():.1f}\")\n",
    "    print(f\"Median age: {titanic_clean['Age'].median():.1f}\")\n",
    "    print(f\"Standard deviation of age: {titanic_clean['Age'].std():.1f}\")\n",
    "\n",
    "if 'Fare' in titanic_clean.columns:\n",
    "    print(f\"Average fare: ${titanic_clean['Fare'].mean():.2f}\")\n",
    "    print(f\"Maximum fare: ${titanic_clean['Fare'].max():.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TFjxj3fb2DSr",
    "outputId": "2755effe-cb4b-4c17-9377-4221031c1745"
   },
   "outputs": [],
   "source": [
    "print(\"\\n7.2 Value Counts:\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "# Count unique values\n",
    "if 'Sex' in titanic_clean.columns:\n",
    "    print(\"Sex distribution:\")\n",
    "    print(titanic_clean['Sex'].value_counts())\n",
    "\n",
    "if 'Pclass' in titanic_clean.columns:\n",
    "    print(\"\\nClass distribution:\")\n",
    "    print(titanic_clean['Pclass'].value_counts().sort_index())\n",
    "\n",
    "# Proportions\n",
    "if 'Survived' in titanic_clean.columns:\n",
    "    print(\"\\nSurvival rate:\")\n",
    "    survival_rate = titanic_clean['Survived'].value_counts(normalize=True)\n",
    "    print(survival_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XIxhNjL_2DVW",
    "outputId": "903eb58d-4fad-46ee-e25d-23970aff731e"
   },
   "outputs": [],
   "source": [
    "print(\"\\n7.3 GroupBy Operations:\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "# Group by single column\n",
    "if 'Sex' in titanic_clean.columns and 'Age' in titanic_clean.columns:\n",
    "    age_by_sex = titanic_clean.groupby('Sex')['Age'].mean()\n",
    "    print(\"Average age by sex:\")\n",
    "    print(age_by_sex)\n",
    "\n",
    "# Group by multiple columns\n",
    "if 'Sex' in titanic_clean.columns and 'Pclass' in titanic_clean.columns:\n",
    "    survival_by_sex_class = titanic_clean.groupby(['Sex', 'Pclass'])['Survived'].mean()\n",
    "    print(\"\\nSurvival rate by sex and class:\")\n",
    "    print(survival_by_sex_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cbGC7tos2zlD",
    "outputId": "b5664b34-e169-4eeb-c509-3910378bc2f9"
   },
   "outputs": [],
   "source": [
    "# Multiple aggregations\n",
    "print(\"\\n7.4 Multiple Aggregation Functions:\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "if 'Fare' in titanic_clean.columns and 'Pclass' in titanic_clean.columns:\n",
    "    fare_stats = titanic_clean.groupby('Pclass')['Fare'].agg(['mean', 'median', 'std', 'count'])\n",
    "    print(\"Fare statistics by class:\")\n",
    "    print(fare_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "M6nhrHIL21Ne",
    "outputId": "813ad04b-925d-4835-ab31-be81f9d86557"
   },
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 8. DATA MERGING AND JOINING\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"8. DATA MERGING AND JOINING\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Create sample datasets for merging\n",
    "print(\"\\n8.1 Creating Sample Data for Merging:\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "# Passenger details\n",
    "passenger_details = pd.DataFrame({\n",
    "    'passenger_id': [1, 2, 3, 4, 5],\n",
    "    'name': ['Alice Johnson', 'Bob Smith', 'Charlie Brown', 'Diana Prince', 'Eve Wilson'],\n",
    "    'ticket_class': [1, 2, 3, 1, 2]\n",
    "})\n",
    "\n",
    "# Ticket information\n",
    "ticket_info = pd.DataFrame({\n",
    "    'passenger_id': [1, 2, 3, 6, 7],\n",
    "    'ticket_number': ['A123', 'B456', 'C789', 'D012', 'E345'],\n",
    "    'fare_paid': [100, 75, 50, 120, 80]\n",
    "})\n",
    "\n",
    "print(\"Passenger Details:\")\n",
    "print(passenger_details)\n",
    "print(\"\\nTicket Information:\")\n",
    "print(ticket_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KJTbeJP621Ri",
    "outputId": "647c370c-18ba-4bed-b991-0ba9d620d86c"
   },
   "outputs": [],
   "source": [
    "print(\"\\n8.2 Different Types of Merges:\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "# Inner join (default)\n",
    "inner_merge = pd.merge(passenger_details, ticket_info, on='passenger_id')\n",
    "print(\"Inner Join (only matching records):\")\n",
    "print(inner_merge)\n",
    "\n",
    "# Left join\n",
    "left_merge = pd.merge(passenger_details, ticket_info, on='passenger_id', how='left')\n",
    "print(\"\\nLeft Join (all records from left table):\")\n",
    "print(left_merge)\n",
    "\n",
    "# Right join\n",
    "right_merge = pd.merge(passenger_details, ticket_info, on='passenger_id', how='right')\n",
    "print(\"\\nRight Join (all records from right table):\")\n",
    "print(right_merge)\n",
    "\n",
    "# Outer join\n",
    "outer_merge = pd.merge(passenger_details, ticket_info, on='passenger_id', how='outer')\n",
    "print(\"\\nOuter Join (all records from both tables):\")\n",
    "print(outer_merge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WiBZCMe-21UP",
    "outputId": "8f2f57d7-86ef-4039-c7a0-e4c8e07dd338"
   },
   "outputs": [],
   "source": [
    "print(\"\\n8.3 Merge with Different Column Names:\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "# Create data with different column names\n",
    "passenger_info = pd.DataFrame({\n",
    "    'id': [1, 2, 3],\n",
    "    'passenger_name': ['Alice', 'Bob', 'Charlie']\n",
    "})\n",
    "\n",
    "booking_info = pd.DataFrame({\n",
    "    'passenger_id': [1, 2, 4],\n",
    "    'booking_date': ['2024-01-01', '2024-01-02', '2024-01-03']\n",
    "})\n",
    "\n",
    "# Merge with different column names\n",
    "merge_diff_names = pd.merge(passenger_info, booking_info,\n",
    "                          left_on='id', right_on='passenger_id', how='inner')\n",
    "print(\"Merge with different column names:\")\n",
    "print(merge_diff_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X29URpJM21W6",
    "outputId": "6e7ae99a-829b-4f7f-af45-af17205bddc9"
   },
   "outputs": [],
   "source": [
    "print(\"\\n8.4 Concatenation:\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "# Concatenate DataFrames vertically\n",
    "df1 = pd.DataFrame({'A': [1, 2], 'B': [3, 4]})\n",
    "df2 = pd.DataFrame({'A': [5, 6], 'B': [7, 8]})\n",
    "\n",
    "concat_vertical = pd.concat([df1, df2], ignore_index=True)\n",
    "print(\"Vertical concatenation:\")\n",
    "print(concat_vertical)\n",
    "\n",
    "# Concatenate horizontally\n",
    "concat_horizontal = pd.concat([df1, df2], axis=1)\n",
    "print(\"\\nHorizontal concatenation:\")\n",
    "print(concat_horizontal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oG-bNiUpLwgz",
    "outputId": "869062b2-f091-4cca-8f97-9b8c01b3553c"
   },
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 9. PIVOT TABLES AND RESHAPING\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"9. PIVOT TABLES AND RESHAPING\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\\n9.1 Pivot Tables:\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "# Create a pivot table\n",
    "if 'Sex' in titanic_clean.columns and 'Pclass' in titanic_clean.columns and 'Survived' in titanic_clean.columns:\n",
    "    pivot_survival = pd.pivot_table(\n",
    "        titanic_clean,\n",
    "        values='Survived',\n",
    "        index='Sex',\n",
    "        columns='Pclass',\n",
    "        aggfunc='mean',\n",
    "        fill_value=0\n",
    "    )\n",
    "    print(\"Survival rate by sex and class (Pivot Table):\")\n",
    "    print(pivot_survival)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ALUmoyHw3Gpy",
    "outputId": "ce9c2fac-87e9-476b-e4ce-7716de43d994"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Pivot table with multiple values\n",
    "if 'Age' in titanic_clean.columns and 'Fare' in titanic_clean.columns:\n",
    "    pivot_multiple = pd.pivot_table(\n",
    "        titanic_clean,\n",
    "        values=['Age', 'Fare'],\n",
    "        index='Sex',\n",
    "        columns='Pclass',\n",
    "        aggfunc='mean',\n",
    "        fill_value=0\n",
    "    )\n",
    "    print(\"\\nAge and Fare by sex and class:\")\n",
    "    print(pivot_multiple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "W_6oiE5C3Gye",
    "outputId": "c5eda9e3-0796-47ec-bfe6-b76e81c08a5e"
   },
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 10. ADVANCED OPERATIONS\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"10. ADVANCED OPERATIONS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\\n10.1 Index Operations:\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "# Set index\n",
    "if 'Age' in titanic_clean.columns:\n",
    "    df_with_index = titanic_clean.copy()\n",
    "    df_with_index = df_with_index.set_index('Age')\n",
    "    print(f\"Shape after setting age as index: {df_with_index.shape}\")\n",
    "    print(\"First few rows with age as index:\")\n",
    "    print(df_with_index.head(3))\n",
    "\n",
    "    # Reset index\n",
    "    df_reset = df_with_index.reset_index()\n",
    "    print(f\"\\nShape after resetting index: {df_reset.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MbfU6IBB3G2p",
    "outputId": "57fc506f-1b2a-41ca-f29e-caadf030ab4c"
   },
   "outputs": [],
   "source": [
    "print(\"\\n10.2 Apply Lambda Functions:\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "# Apply function to create new columns\n",
    "if 'Age' in titanic_clean.columns:\n",
    "    titanic_clean['Age_group'] = titanic_clean['Age'].apply(\n",
    "        lambda x: 'Child' if x < 18 else ('Adult' if x < 60 else 'Senior')\n",
    "    )\n",
    "\n",
    "    print(\"Age group distribution:\")\n",
    "    print(titanic_clean['Age_group'].value_counts())\n",
    "\n",
    "# Apply function to multiple columns\n",
    "def categorize_passenger(row):\n",
    "    if row['Pclass'] == 1:\n",
    "        return 'First Class'\n",
    "    elif row['Pclass'] == 2:\n",
    "        return 'Second Class'\n",
    "    else:\n",
    "        return 'Third Class'\n",
    "\n",
    "titanic_clean['class_name'] = titanic_clean.apply(categorize_passenger, axis=1)\n",
    "print(\"\\nClass name distribution:\")\n",
    "print(titanic_clean['class_name'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ea-XDBX14Bzs",
    "outputId": "ae787ad6-a5d7-4d38-dd10-4d72f9c73a3a"
   },
   "outputs": [],
   "source": [
    "print(\"\\n10.3 Working with Dates:\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "# Create sample date data\n",
    "date_range = pd.date_range(start='2024-01-01', end='2024-01-10', freq='D')\n",
    "date_df = pd.DataFrame({\n",
    "    'date': date_range,\n",
    "    'value': np.random.randn(len(date_range))\n",
    "})\n",
    "\n",
    "print(\"Sample date data:\")\n",
    "print(date_df.head())\n",
    "\n",
    "# Extract date components\n",
    "date_df['year'] = date_df['date'].dt.year\n",
    "date_df['month'] = date_df['date'].dt.month\n",
    "date_df['dayofweek'] = date_df['date'].dt.dayofweek\n",
    "date_df['weekday_name'] = date_df['date'].dt.day_name()\n",
    "\n",
    "print(\"\\nDate with extracted components:\")\n",
    "print(date_df[['date', 'year', 'month', 'dayofweek', 'weekday_name']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "D5xXzZAA4F1g",
    "outputId": "f034ee67-160b-4dee-d250-9dd06a977fb1"
   },
   "outputs": [],
   "source": [
    "print(\"\\n10.4 Data Validation and Quality Checks:\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "# Check for duplicates\n",
    "duplicates = titanic_clean.duplicated().sum()\n",
    "print(f\"Number of duplicate rows: {duplicates}\")\n",
    "\n",
    "# Check data ranges\n",
    "if 'Age' in titanic_clean.columns:\n",
    "    invalid_ages = titanic_clean[(titanic_clean['Age'] < 0) | (titanic_clean['Age'] > 150)]\n",
    "    print(f\"Invalid ages (< 0 or > 150): {len(invalid_ages)}\")\n",
    "\n",
    "# Memory usage\n",
    "print(f\"\\nDataset memory usage: {titanic_clean.memory_usage(deep=True).sum() / 1024:.2f} KB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TJGwrB5YTYMG",
    "outputId": "eba938de-21a8-4ba2-9e7d-7e00274666a1"
   },
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"SUMMARY AND BEST PRACTICES\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\"\"\n",
    "Key Pandas Concepts Covered:\n",
    "1. Series and DataFrame creation and manipulation\n",
    "2. Data loading and exploration\n",
    "3. Data selection and indexing (iloc, loc)\n",
    "4. Missing value handling (dropna, fillna)\n",
    "5. Data filtering and querying (isin, query)\n",
    "6. Aggregation and grouping operations\n",
    "7. Data merging and joining\n",
    "8. Pivot tables and data reshaping\n",
    "9. Advanced operations (apply, dates)\n",
    "\n",
    "Next Steps:\n",
    "- Practice with different datasets\n",
    "\"\"\")\n",
    "\n",
    "# Final dataset summary\n",
    "print(f\"\\nFinal cleaned dataset shape: {titanic_clean.shape}\")\n",
    "print(f\"Columns: {titanic_clean.columns.tolist()}\")\n",
    "print(\"\\nData cleaning complete! Dataset ready for analysis.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K7x5jhaViSH-"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
